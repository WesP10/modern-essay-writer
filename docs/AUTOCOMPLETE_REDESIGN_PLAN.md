# ğŸ¯ Autocomplete Redesign Plan

## Overview
Restructuring the autocomplete system into three distinct, modular engines with clear performance targets and separation of concerns.

---

## ğŸ—ï¸ Architecture

```
User Types
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ORCHESTRATOR                            â”‚
â”‚  Decides which engine(s) to invoke based on context     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ â†“ â†“
    â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â†“                        â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRIE ENGINE â”‚    â”‚  N-GRAM ENGINE   â”‚   â”‚  LLM ENGINE  â”‚
â”‚  <10ms      â”‚    â”‚    <50ms         â”‚   â”‚  200-500ms   â”‚
â”‚  Word-level â”‚    â”‚  Phrase-level    â”‚   â”‚  Contextual  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Layer Specifications

### **Layer 1: Trie Engine** (Every keystroke)
**Purpose:** Ultra-fast word completion  
**Trigger:** Every keystroke while typing a word  
**Target Latency:** <10ms  
**Output:** Top 5-10 word completions with frequency scores

**Implementation:**
- **Compressed Radix Trie** (reduces memory by ~40%)
- **Frequency-weighted nodes** for smart ranking
- **LRU cache** for recent prefix queries (1000 entries)
- **Dictionary size:** 500k+ words (expandable)

**Data Structure:**
```javascript
{
  root: {
    'a': {
      'c': {
        'a': { 
          'd': { 
            'e': { 
              'm': { 
                'i': { 
                  'c': { 
                    isWord: true, 
                    frequency: 8523,
                    word: 'academic'
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
```

---

### **Layer 2: N-gram Engine** (After word boundary)
**Purpose:** Short phrase prediction  
**Trigger:** Space bar pressed (word boundary detected)  
**Target Latency:** <50ms  
**Output:** Top 3-5 phrase continuations

**Implementation:**
- **Bi-grams, Tri-grams, 4-grams, 5-grams**
- **Kneser-Ney smoothing** for unseen n-grams
- **Context window:** Last 3 words typed
- **Precomputed probabilities** stored in hash map

**Algorithm:**
```
P(wâ‚ƒ | wâ‚, wâ‚‚) = Count(wâ‚, wâ‚‚, wâ‚ƒ) / Count(wâ‚, wâ‚‚)

With smoothing:
P_KN(wâ‚ƒ | wâ‚, wâ‚‚) = max(Count(wâ‚,wâ‚‚,wâ‚ƒ) - Î´, 0) / Count(wâ‚,wâ‚‚) + Î» Ã— P_KN(wâ‚ƒ | wâ‚‚)
```

**Training Corpus:**
- Academic writing samples
- Essay databases
- Research papers
- Common phrase patterns

**Example:**
```javascript
Bigrams: {
  "in": ["addition", "conclusion", "fact", "summary", "contrast"],
  "on": ["the", "behalf", "account", "average"],
  "for": ["example", "instance", "this", "the"]
}

Trigrams: {
  "in_addition": ["to", "the", "it"],
  "on_the": ["other", "contrary", "basis", "whole"],
  "for_this": ["reason", "purpose", "study"]
}
```

---

### **Layer 3: LLM Engine** (Idle timeout)
**Purpose:** Contextual, long-form suggestions  
**Trigger:** User stops typing for 2-3 seconds  
**Target Latency:** 200-500ms (async, non-blocking)  
**Output:** 1-3 contextual suggestions (shown as ghost text)

**Rules:**
- **If blank/new line:** Suggest sentence starters
- **If mid-word:** Only complete current word (fallback if Trie fails)
- **If after sentence:** Suggest next sentence continuation
- **Context window:** Last 200 characters

**Optimization:**
- **Smaller model:** Use gemma3:1b or distilled models
- **Async execution:** Non-blocking UI
- **Visual distinction:** Ghost text (gray, italic)
- **Cache:** Store recent contextâ†’suggestion mappings

**Throttling Logic:**
```javascript
- If typing: LLM disabled
- If idle 2s + context >50 chars: LLM enabled
- If LLM call in progress: Queue, don't duplicate
- Max 1 LLM call per 3 seconds
```

---

## ğŸ¯ Decision Tree

```
User types character
    â†“
Is it mid-word?
    â”œâ”€â”€ YES â†’ Trie Engine (instant word completions)
    â””â”€â”€ NO â†’ Is it a space?
            â”œâ”€â”€ YES â†’ N-gram Engine (phrase suggestions)
            â””â”€â”€ NO â†’ Is user idle >2s?
                    â”œâ”€â”€ YES â†’ LLM Engine (contextual)
                    â””â”€â”€ NO â†’ Wait
```

---

## ğŸ“ˆ Performance Targets

| Engine | Trigger | Latency | Success Rate |
|--------|---------|---------|--------------|
| Trie | Every keystroke | <10ms | 85% relevance |
| N-gram | Word boundary | <50ms | 90% relevance |
| LLM | Idle timeout | 200-500ms | 95% relevance |

**Overall Goals:**
- 95% of interactions <50ms
- 99% of interactions <500ms
- Zero blocking operations
- Smooth, imperceptible transitions

---

## ğŸ—‚ï¸ File Structure

```
backend/
  services/
    autocomplete/
      TrieEngine.js           # Fast word completion
      NgramEngine.js          # Phrase prediction
      LLMEngine.js            # Contextual suggestions
      AutocompleteOrchestrator.js  # Coordinates all engines
  data/
    dictionaries/
      words-500k.json         # Large word dictionary
      academic-vocab.json     # Academic-specific words
    ngrams/
      bigrams.json           # Precomputed bigrams
      trigrams.json          # Precomputed trigrams
      fourgrams.json         # Precomputed 4-grams
  training/
    build-ngrams.js          # Script to build n-gram models
    train-corpus.txt         # Training text corpus
```

---

## ğŸ”§ Implementation Steps

### Phase 1: Trie Engine (Week 1)
1. âœ… Implement compressed radix trie
2. âœ… Load 500k word dictionary with frequencies
3. âœ… Add LRU caching layer
4. âœ… Benchmark: Ensure <10ms lookups
5. âœ… Unit tests for edge cases

### Phase 2: N-gram Engine (Week 2)
1. âœ… Collect training corpus (academic essays, papers)
2. âœ… Build n-gram model (bi/tri/4/5-grams)
3. âœ… Implement Kneser-Ney smoothing
4. âœ… Precompute probabilities, store in efficient format
5. âœ… Benchmark: Ensure <50ms lookups
6. âœ… Unit tests for phrase prediction

### Phase 3: LLM Engine (Week 3)
1. âœ… Implement idle detection (debounce)
2. âœ… Add async LLM call with timeout
3. âœ… Implement throttling logic
4. âœ… Add context-aware rules (blank/mid-word/sentence)
5. âœ… Cache LLM results
6. âœ… Visual distinction (ghost text API)

### Phase 4: Orchestrator (Week 4)
1. âœ… Build decision tree logic
2. âœ… Merge results from multiple engines
3. âœ… Implement conflict resolution
4. âœ… Add telemetry (which engine served result)
5. âœ… Integration tests

### Phase 5: Frontend Integration (Week 5)
1. âœ… Update Editor component for idle detection
2. âœ… Implement ghost text rendering
3. âœ… Add visual indicators (engine badges)
4. âœ… Performance monitoring
5. âœ… UX testing

---

## ğŸ“Š Data Preparation

### Dictionary Sources
- **SCOWL (500k+ words):** http://wordlist.aspell.net/
- **Google Books Ngrams:** Word frequencies
- **Academic Word List (AWL):** Specialized vocabulary
- **User-contributed words:** Dynamic additions

### N-gram Training Corpus
- **Academic essays:** 1000+ sample essays
- **Research papers:** 500+ abstracts
- **Common phrases:** Manually curated
- **Total corpus size:** ~5-10 million words

### Precomputation
```bash
# Build n-grams
node backend/training/build-ngrams.js

# Output:
# - bigrams.json (~2 MB)
# - trigrams.json (~10 MB)
# - fourgrams.json (~20 MB)
# Total: ~32 MB (gzipped: ~8 MB)
```

---

## ğŸ¨ UX Improvements

### Visual Feedback
```
User types: "in a"

Trie suggestions (instant):
  in a[ddition]    [Trie]
  in a[ccordance]  [Trie]
  in a[ll]         [Trie]

N-gram suggestions (after space):
  in addition to   [N-gram]
  in accordance with [N-gram]

LLM suggestion (after 2s idle):
  "in addition to this, the evidence suggests..." [LLM] (ghost text)
```

### Dropdown Design
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ addition        [Trie]  95%            â”‚  â† Selected
â”‚ in addition to  [N-gram] 92%           â”‚
â”‚ accordance      [Trie]  88%            â”‚
â”‚ all likelihood  [N-gram] 85%           â”‚
â”‚ a similar vein  [N-gram] 82%           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ’¡ in addition to this, the evidence... â”‚  â† Ghost text (LLM)
â”‚    (Press Tab to accept)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testing Strategy

### Unit Tests
- Trie: Prefix lookups, edge cases, memory usage
- N-gram: Probability calculations, smoothing
- LLM: Throttling, caching, context rules

### Integration Tests
- Orchestrator decision tree
- Multi-engine result merging
- Cache coherence

### Performance Tests
- Load test: 1000 queries/second
- Latency test: P50, P95, P99
- Memory profiling

### UX Tests
- A/B testing different trigger timings
- User feedback on suggestion quality
- Acceptance rate tracking

---

## ğŸ“ˆ Success Metrics

### Technical Metrics
- **Trie latency:** <10ms (99th percentile)
- **N-gram latency:** <50ms (99th percentile)
- **LLM latency:** <500ms (95th percentile)
- **Memory usage:** <100 MB (all engines combined)
- **Cache hit rate:** >70%

### User Metrics
- **Acceptance rate:** >40% (industry standard: 25-30%)
- **Keystroke savings:** >30%
- **User satisfaction:** >4.0/5.0
- **No perceived lag:** <5% user complaints

---

## ğŸ”’ Scalability Considerations

### Memory Management
- Trie: ~50 MB (500k words)
- N-grams: ~32 MB (compressed)
- Caches: ~20 MB
- **Total:** ~100 MB

### Horizontal Scaling
- All engines stateless (except caches)
- Can run on separate processes
- Redis for shared cache layer

### Future Enhancements
- WebAssembly trie for browser-side completion
- Federated learning for personalization
- Domain-specific n-gram models
- Real-time model updates

---

## ğŸš€ Migration Plan

### Week 1: Parallel Development
- Keep existing system running
- Build new engines alongside
- Feature flag for testing

### Week 2: A/B Testing
- 10% traffic to new system
- Monitor metrics
- Fix bugs

### Week 3: Gradual Rollout
- 50% traffic
- Performance tuning
- User feedback

### Week 4: Full Migration
- 100% traffic
- Deprecate old system
- Documentation

---

## ğŸ“š References

- **Radix Trie:** https://en.wikipedia.org/wiki/Radix_tree
- **Kneser-Ney Smoothing:** https://www.cs.cornell.edu/courses/cs4740/2014sp/lectures/smoothing+backoff.pdf
- **Google N-gram Viewer:** https://books.google.com/ngrams
- **Academic Word List:** https://www.victoria.ac.nz/lals/resources/academicwordlist

---

## âœ… Action Items

**Immediate (This Week):**
- [ ] Set up new file structure
- [ ] Download 500k word dictionary
- [ ] Implement basic TrieEngine
- [ ] Benchmark current vs new system

**Short-term (Next 2 Weeks):**
- [ ] Complete TrieEngine with caching
- [ ] Build n-gram training pipeline
- [ ] Implement NgramEngine
- [ ] Create Orchestrator skeleton

**Medium-term (Next Month):**
- [ ] LLM throttling and async execution
- [ ] Frontend integration (ghost text)
- [ ] A/B testing framework
- [ ] Performance monitoring dashboard

---

**This plan transforms the autocomplete from "clunky" to "blazing fast + intelligent"** ğŸš€
